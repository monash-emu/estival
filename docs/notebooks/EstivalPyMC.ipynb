{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "821820a8",
   "metadata": {},
   "source": [
    "# Estival/PyMC\n",
    "\n",
    "In this notebook, we will build a BayesianCompartmentalModel, and calibrate it using PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install in colab\n",
    "#!pip install estival==0.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required for parallel evaluation in notebooks\n",
    "# Note that if running under (non-WSL) Windows, you should\n",
    "# disable this line, and use single threaded evaluation in pymc\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import summer2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d790a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summer2.extras import test_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = test_models.sir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0844c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "defp = m.get_default_parameters()\n",
    "defp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bde71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.run({\"contact_rate\": 0.5, \"recovery_rate\": 0.4})\n",
    "do_def = m.get_derived_outputs_df()\n",
    "obs_clean = do_def[\"incidence\"].iloc[0:50]\n",
    "obs_noisy = obs_clean * np.exp(np.random.normal(0.0,0.2,len(obs_clean)))\n",
    "obs_clean.plot()\n",
    "obs_noisy.plot(style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following imports are the 'building blocks' of estival models\n",
    "\n",
    "# Targets represent data we are trying to fit to\n",
    "from estival import targets as est\n",
    "\n",
    "# We specify parameters using (Bayesian) priors\n",
    "from estival import priors as esp\n",
    "\n",
    "# Finally we combine these with our summer2 model in a BayesianCompartmentalModel (BCM)\n",
    "from estival.model import BayesianCompartmentalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24785c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a Truncated normal target with a free dispersion parameter\n",
    "targets = [\n",
    "    est.TruncatedNormalTarget(\"incidence\", obs_noisy, (0.0,np.inf),\n",
    "        esp.UniformPrior(\"incidence_dispersion\",(0.1, obs_noisy.max()*0.1)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29170d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform priors over our 2 model parameters\n",
    "priors = [\n",
    "    esp.UniformPrior(\"contact_rate\", (0.01,1.0)),\n",
    "    esp.TruncNormalPrior(\"recovery_rate\", 0.5, 0.2, (0.01,1.0)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BayesianCompartmentalModel class is the primary entry point to all optimization and calibration\n",
    "# methods in estival\n",
    "# It takes a CompartmentalModel object, default parameters, priors, and targets\n",
    "# The default parameters will be used as fixed values when no prior is specified for a given parameter\n",
    "\n",
    "bcm = BayesianCompartmentalModel(m, defp, priors, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.calibration import pymc as epm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # This is all you need - a single call to use_model\n",
    "    # include_ll will optionally output the BCM loglikelihood as a sampled value\n",
    "    # It is recommended this value be left at the default (False),\n",
    "    # but we include it in this notebook for convenience\n",
    "\n",
    "    variables = epm.use_model(bcm, include_ll=True)\n",
    "    \n",
    "    # The log-posterior value can also be output, but may incur additional overhead\n",
    "    # Use jacobian=False to get the unwarped value (ie just the 'native' density of the priors\n",
    "    # without transformation correction factors)\n",
    "    # pm.Deterministic(\"logp\", model.logp(jacobian=False))\n",
    "    \n",
    "    # Now call a sampler using the variables from use_model\n",
    "    # In this case we use the Differential Evolution Metropolis sampler\n",
    "    # See the PyMC docs for more details\n",
    "    idata_mh = pm.sample(step=[pm.DEMetropolis(variables)], draws=4000, tune=1000,cores=4,chains=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f063066c",
   "metadata": {},
   "source": [
    "## Using arviz to examine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata_mh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48174240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - select some subset out of the resulting trace - useful if\n",
    "# you require additional burnin\n",
    "# subset = idata_mh.sel(draw=slice(500, None), groups=\"posterior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata_mh, figsize=(16,3.2*len(idata_mh.posterior)),compact=False);#, lines=[(\"m\", {}, mtrue), (\"c\", {}, ctrue)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc584ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata_mh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have included the loglikelihood in our outputs, then obtaining the MLE is simple\n",
    "# Note that it is generally far more efficient to generate the loglikelihood as a\n",
    "# separate step, but we follow the 'easy path' in this notebook for clarity\n",
    "\n",
    "caldf = idata_mh.to_dataframe(groups=\"posterior\")\n",
    "ll_sorted = caldf.sort_values(by=\"loglike\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95444c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply get the first item from our sorted Dataframe\n",
    "\n",
    "mle_params = ll_sorted.iloc[0][list(bcm.priors)].to_dict()\n",
    "mle_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4607422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see, this is exactly the value output from the original BCM\n",
    "bcm.loglikelihood(**mle_params), ll_sorted.iloc[0][\"loglike\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with these parameters\n",
    "mle_res = bcm.run(mle_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and plot some results\n",
    "variable = \"incidence\"\n",
    "\n",
    "pd.Series(mle_res.derived_outputs[variable]).plot(title = f\"{variable} (MLE)\")\n",
    "bcm.targets[variable].data.plot(style='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some basic uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093339f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_outputs(bcm, idata, n_samples):\n",
    "    caldf = idata.to_dataframe(groups=\"posterior\")\n",
    "    caldf = caldf[list(bcm.priors)]\n",
    "    draws = caldf.index\n",
    "    sel_draws = np.random.choice(draws, n_samples, False)\n",
    "    samples = caldf.loc[sel_draws]\n",
    "    \n",
    "    all_res = []\n",
    "    for k,v in samples.iterrows():\n",
    "        cur_sample = v.to_dict()\n",
    "        all_res.append(bcm.run(cur_sample))\n",
    "        \n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f65137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with n_samples to get a sense of what is required to accurately represent the posterior\n",
    "all_res = sample_outputs(bcm, idata_mh, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b900e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty_quantiles(all_res, quantiles, variable):\n",
    "    stacked_incidence = np.stack([res.derived_outputs[variable] for res in all_res])\n",
    "    return pd.DataFrame(np.quantile(stacked_incidence, quantiles, axis=0).T, columns=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"incidence\"\n",
    "quantiles = (0.025,0.25,0.5,0.75,0.975)\n",
    "\n",
    "udf = get_uncertainty_quantiles(all_res, quantiles, variable)\n",
    "\n",
    "fig = udf.plot(title=variable,alpha=0.7)\n",
    "pd.Series(mle_res.derived_outputs[variable]).plot(style='--')\n",
    "bcm.targets[variable].data.plot(style='.',color=\"black\", ms=3, alpha=0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9032fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
